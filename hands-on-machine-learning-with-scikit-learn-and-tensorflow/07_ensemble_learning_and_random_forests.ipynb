{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifiers\n",
    "- Majority-vote classifier --- hard voting classifier\n",
    "![hard voting classifier](./pics/majority-vote-classifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.912\n",
      "SVC 0.888\n",
      "VotingClassifier 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.888\n",
      "SVC 0.888\n",
      "VotingClassifier 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/trierbo/miniconda2/envs/data-science/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "print(bag_clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36144578, 0.63855422],\n",
       "       [0.33526012, 0.66473988],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.075     , 0.925     ],\n",
       "       [0.36065574, 0.63934426],\n",
       "       [0.02234637, 0.97765363],\n",
       "       [0.97727273, 0.02272727],\n",
       "       [0.95652174, 0.04347826],\n",
       "       [0.81034483, 0.18965517],\n",
       "       [0.00609756, 0.99390244],\n",
       "       [0.82010582, 0.17989418],\n",
       "       [0.81564246, 0.18435754],\n",
       "       [0.98369565, 0.01630435],\n",
       "       [0.06432749, 0.93567251],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97222222, 0.02777778],\n",
       "       [0.93714286, 0.06285714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.36979167, 0.63020833],\n",
       "       [0.915     , 0.085     ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96385542, 0.03614458],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62921348, 0.37078652],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17486339, 0.82513661],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39247312, 0.60752688],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21287129, 0.78712871],\n",
       "       [0.36875   , 0.63125   ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01587302, 0.98412698],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.87978142, 0.12021858],\n",
       "       [0.96825397, 0.03174603],\n",
       "       [0.9516129 , 0.0483871 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08900524, 0.91099476],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0060241 , 0.9939759 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [1.        , 0.        ],\n",
       "       [0.80188679, 0.19811321],\n",
       "       [0.4127907 , 0.5872093 ],\n",
       "       [0.9939759 , 0.0060241 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7173913 , 0.2826087 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85405405, 0.14594595],\n",
       "       [1.        , 0.        ],\n",
       "       [0.59659091, 0.40340909],\n",
       "       [0.10497238, 0.89502762],\n",
       "       [0.67647059, 0.32352941],\n",
       "       [0.88586957, 0.11413043],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18579235, 0.81420765],\n",
       "       [0.88268156, 0.11731844],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03954802, 0.96045198],\n",
       "       [0.02941176, 0.97058824],\n",
       "       [0.35204082, 0.64795918],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.82738095, 0.17261905],\n",
       "       [0.01015228, 0.98984772],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.25139665, 0.74860335],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92631579, 0.07368421],\n",
       "       [0.74157303, 0.25842697],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21212121, 0.78787879],\n",
       "       [0.60693642, 0.39306358],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04494382, 0.95505618],\n",
       "       [0.4972973 , 0.5027027 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25490196, 0.74509804],\n",
       "       [0.48989899, 0.51010101],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03296703, 0.96703297],\n",
       "       [0.99415205, 0.00584795],\n",
       "       [0.26153846, 0.73846154],\n",
       "       [0.9281768 , 0.0718232 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.74698795, 0.25301205],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93513514, 0.06486486],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.24242424, 0.75757576],\n",
       "       [0.96791444, 0.03208556],\n",
       "       [0.25      , 0.75      ],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01136364, 0.98863636],\n",
       "       [0.66492147, 0.33507853],\n",
       "       [0.39053254, 0.60946746],\n",
       "       [0.38068182, 0.61931818],\n",
       "       [0.89071038, 0.10928962],\n",
       "       [0.88888889, 0.11111111],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.84408602, 0.15591398],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0295858 , 0.9704142 ],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01069519, 0.98930481],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01694915, 0.98305085],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96132597, 0.03867403],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39572193, 0.60427807],\n",
       "       [0.22424242, 0.77575758],\n",
       "       [0.00578035, 0.99421965],\n",
       "       [0.        , 1.        ],\n",
       "       [0.31515152, 0.68484848],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00497512, 0.99502488],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98901099, 0.01098901],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.68539326, 0.31460674],\n",
       "       [0.90957447, 0.09042553],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04545455, 0.95454545],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02020202, 0.97979798],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95108696, 0.04891304],\n",
       "       [0.7311828 , 0.2688172 ],\n",
       "       [0.65      , 0.35      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17032967, 0.82967033],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96153846, 0.03846154],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39153439, 0.60846561],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.23333333, 0.76666667],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.78571429, 0.21428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08287293, 0.91712707],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0255102 , 0.9744898 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05263158, 0.94736842],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79787234, 0.20212766],\n",
       "       [0.        , 1.        ],\n",
       "       [0.86624204, 0.13375796],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.1758794 , 0.8241206 ],\n",
       "       [0.21081081, 0.78918919],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22754491, 0.77245509],\n",
       "       [0.97461929, 0.02538071],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.53513514, 0.46486486],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07821229, 0.92178771],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [0.01463415, 0.98536585],\n",
       "       [1.        , 0.        ],\n",
       "       [0.37572254, 0.62427746],\n",
       "       [0.08433735, 0.91566265],\n",
       "       [0.52604167, 0.47395833],\n",
       "       [0.58080808, 0.41919192],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.63687151, 0.36312849],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25628141, 0.74371859],\n",
       "       [0.83783784, 0.16216216],\n",
       "       [0.06818182, 0.93181818],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8258427 , 0.1741573 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00606061, 0.99393939],\n",
       "       [0.11891892, 0.88108108],\n",
       "       [0.01324503, 0.98675497],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84816754, 0.15183246],\n",
       "       [0.17679558, 0.82320442],\n",
       "       [0.9516129 , 0.0483871 ],\n",
       "       [0.01015228, 0.98984772],\n",
       "       [0.61463415, 0.38536585],\n",
       "       [0.07407407, 0.92592593],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [0.82407407, 0.17592593],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96511628, 0.03488372],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.32972973, 0.67027027],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.88020833, 0.11979167],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.78350515, 0.21649485],\n",
       "       [0.9197861 , 0.0802139 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.70053476, 0.29946524],\n",
       "       [0.57988166, 0.42011834],\n",
       "       [0.        , 1.        ],\n",
       "       [0.89617486, 0.10382514],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84782609, 0.15217391],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.71428571, 0.28571429],\n",
       "       [0.09708738, 0.90291262],\n",
       "       [0.53672316, 0.46327684],\n",
       "       [0.25414365, 0.74585635],\n",
       "       [0.        , 1.        ],\n",
       "       [0.89361702, 0.10638298],\n",
       "       [0.81052632, 0.18947368],\n",
       "       [0.01117318, 0.98882682],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02030457, 0.97969543],\n",
       "       [0.95336788, 0.04663212],\n",
       "       [0.95212766, 0.04787234],\n",
       "       [1.        , 0.        ],\n",
       "       [0.53757225, 0.46242775],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99425287, 0.00574713],\n",
       "       [0.02094241, 0.97905759],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98235294, 0.01764706],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01630435, 0.98369565],\n",
       "       [1.        , 0.        ],\n",
       "       [0.11398964, 0.88601036],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36040609, 0.63959391],\n",
       "       [0.05978261, 0.94021739],\n",
       "       [0.21264368, 0.78735632],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98863636, 0.01136364],\n",
       "       [0.17318436, 0.82681564],\n",
       "       [0.98412698, 0.01587302],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95287958, 0.04712042],\n",
       "       [0.2967033 , 0.7032967 ],\n",
       "       [0.99371069, 0.00628931],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02688172, 0.97311828],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02173913, 0.97826087],\n",
       "       [0.63793103, 0.36206897]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "\n",
    "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "- AdaBoost\n",
    "![AdaBoost](./pics/adaboost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted error rate of the j th predictor\n",
    "$$r_j = \\frac{\\sum_{i=1, \\hat{y}_{j}^{(i)} \\neq y^{(i)}}^{m} w^{(i)}}{\\sum_{i=1}^{m}w^{(i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictor weight\n",
    "$$\\alpha_{j} = \\eta \\log{\\frac{1-r_{j}}{r_{j}}}$$\n",
    "$\\eta$ is the learning rate hyperparameter (defaults to 1)\n",
    "\n",
    "- The more accurate the predictor is, the higher its weight will be.\n",
    "- If it is just guessing randomly, then its weight will be close to zero\n",
    "- However, if it is most often wrong (i.e., less accurate than random guessing), then its weight will be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight update rule\n",
    "$$for \\quad i = 1, 2, ..., m \\\\\n",
    "w^{(i)} \\gets\n",
    "\\begin{cases}\n",
    "\\ w^{(i)} \\quad if \\quad \\hat{y_{j}}^{(i)} = y^{(i)} \\\\\n",
    "\\ w^{(i)}\\exp(\\alpha_{j}) \\quad if \\quad \\hat{y_{j}}^{(i)} \\neq y^{(i)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then all the instance weights are normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost predictions\n",
    "$$\\hat{y}(x) = argmax_{k} \\sum_{j=1,\\hat{y}_{j}(x)=k}^{N}\\alpha_{j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf =  AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm='SAMME.R', learning_rate=0.5\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradientboosting](./pics/gradientboosting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=84, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "         for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best model (84 trees)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_error = np.min(errors)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(errors, \"b.-\")\n",
    "plt.plot([bst_n_estimators, bst_n_estimators], [0, min_error], \"k--\")\n",
    "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
    "plt.plot(bst_n_estimators, min_error, \"ko\")\n",
    "plt.text(bst_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
    "plt.axis([0, 120, 0, 0.01])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.title(\"Validation error\", fontsize=14)\n",
    "\n",
    "plt.title(\"Best model (%d trees)\" % bst_n_estimators, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float('inf')\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking\n",
    "![stacking](./pics/stacking.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
